{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "convolutional-neural-networks",
      "graded_item_id": "qO8ng",
      "launcher_item_id": "7XDi8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "CV2 - 01 - Capas_convolucionales.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp572BeRfMnj"
      },
      "source": [
        "# Capas convolucionales: CONV y POOL\n",
        "\n",
        "Vamos a implementar los dos tipos de capas presentadas en la clase teórica. La capa convolucional y la capa de pooling (max y average).\n",
        "\n",
        "**Notación**:\n",
        "- Superíndice $[l]$ denota un elemento de la capa $l^{th}$. \n",
        "    - Ejemplo: $a^{[3]}$ es la activación de la $4^{ta}$ capa. $W^{[3]}$ and $b^{[3]}$ son los parámetros de la $3^{er}$ capa.\n",
        "\n",
        "- Superíndice $(i)$ denota un elemento que pertenece al ejemplo con índice i.\n",
        "    - Ejemplo: $x^{(i)}$ es el iésimo ejemplo de entrada.\n",
        "    \n",
        "- Subíndice $i$ denota a la iésima entrada de un vector.\n",
        "    - Ejemplo: $a^{[l]}_i$ denota la iésima entrada de las activaciones en la capa $l$ (si asumimos una capa Fully Connected).\n",
        "    \n",
        "    \n",
        "- $n_H$, $n_W$ y $n_C$ denotan la altura, el ancho y número de canales de una determinada capa, respectivamente. Si queremos referenciar a una capa específica $l$, se puede escribir $n_H^{[l]}$, $n_W^{[l]}$, $n_C^{[l]}$. \n",
        "- $n_{H_{prev}}$, $n_{W_{prev}}$ y $n_{C_{prev}}$ denotan la altura, el ancho y la cantidad de canales de la capa anterior, respectivamente. Si nos estamos refiriendo a una capa específica $l$, esto puede ser referenciado como  $n_H^{[l-1]}$, $n_W^{[l-1]}$, $n_C^{[l-1]}$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7cb6xBPfMnk"
      },
      "source": [
        "## 1 - Importación de paquetes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RLUt5xhfMnl"
      },
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1) # permite que todas las llamadas a funciones aleatorias sean iguales en todas las corridas"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7vBvuvrfMno"
      },
      "source": [
        "## 2 - Qué vamos a hacer?\n",
        "\n",
        "Hay que implementar los dos elementos fundamentales de una red convolucional. \n",
        "\n",
        "- Funciones convolucionales:\n",
        "    - Zero Padding\n",
        "    - Convolucionar en una ventana\n",
        "    - Paso forward de una convolución\n",
        "    \n",
        "- Funciones de pooling:\n",
        "    - Paso forward de pooling\n",
        "    - Crear una máscara\n",
        "    - Distribuir valores\n",
        "\n",
        "Vamos a implementar todo esto usando funciones elementales de `numpy`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2CYuZc-fMnp"
      },
      "source": [
        "## 3 - Redes Neuronales Convolucionales (Convolutional Neural Networks o CNN)\n",
        "\n",
        "Una capa convolucional transforma un volumen de entrada en un volumen de salida de diferente tamaño:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1PwpyKKNylBN6MJoN2APeNzjXIYZ9yilO\" style=\"width:350px;height:200px;\">\n",
        "\n",
        "En esta parte vamos a implementar una capa convolucional. Primero programamos dos funciones que nos van a ayudar: \n",
        "- zero padding (rellenar con ceros en los bordes)\n",
        "- computar la convolución para un sub-rectángulo de la entrada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sIPA6RdfMnp"
      },
      "source": [
        "### 3.1 - Zero-Padding\n",
        "\n",
        "Zero-padding agrega ceros en los bordes de una imagen:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1JjdIwqA9e6jSrkMHiEV5k97py9LH4sUl\" style=\"width:600px;height:400px;\">\n",
        "<caption><center> <u> <font color='white'> **Figura 1** </u><font color='white'>  : **Zero-Padding**<br> Imagen (3 canales, RGB) con padding de 2. </center></caption>\n",
        "\n",
        "    \n",
        "¿Para qué hacemos zero-padding?\n",
        "\n",
        "- Permite utilizar una capa CONV sin necesariamente dismuniuir la altura y el ancho de los volúmenes. Si construímos una red muy profunda y no usamos esto, la altura/ancho de la imagen se contrairían a medida que avanzamos en las capas. Nos permite hacer una convolución 'same' (misma), o sea que la altura y el ancho de la imagen se preservan para la próxima capa.\n",
        "\n",
        "- Nos permite utilizar mejor la información en el borde de la imagen. Sin padding muy pocos valores de la capa siguiente dependen de los valores en los bordes.\n",
        "\n",
        "**Ejercicio**: Implementar la siguiente función, que completa con ceros todas las imágenes de un batch de ejemplos X. [tip: usar np.pad (https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html)] . Obs.: Si queremos rellenar un array \"a\" de dimensión $(5,5,5,5,5)$ con 1 cero de relleno en la segunda dimensión, 3 ceros de relleno en la cuarta dimensión y ningún relleno en las otras dimensiones, haríamos:\n",
        "```python\n",
        "a = np.pad(a, ((0,0), (1,1), (0,0), (3,3), (0,0)), mode='constant', constant_values = (0,0))\n",
        "```    \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1M69Fo-fMnq"
      },
      "source": [
        "def zero_pad(X, pad):\n",
        "    \"\"\"\n",
        "    Rellenar con bordes con ceros las imágenes del dataset X. El relleno es aplicado a la altura y al ancho de la imagen,\n",
        "    como se ve en la Figura 1.\n",
        "    \n",
        "    Argumento:\n",
        "    X -- array de numpy con dimensiones (m, n_H, n_W, n_C) que representa un batch de m imágenes\n",
        "    pad -- entero, cantidad de relleno alrededor de cada imagen en las direcciones horizontal y vertical\n",
        "    \n",
        "    Retorna:\n",
        "    X_pad -- imagen con ceros agregados de dimensión (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    ### Completar el código ###     \n",
        "    m, n_H, n_W, n_C = X.shape    \n",
        "    X_pad = np.zeros((m,n_H+2*pad,n_W+2*pad,n_C))\n",
        "    X_pad[:,pad:(pad+n_H),pad:(pad+n_W),:] = X\n",
        "    ### fin del código ###\n",
        "    \n",
        "    return X_pad"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJHh4feQfMnu",
        "outputId": "e4a4b1f9-44bf-44f6-9c38-5573043fa84e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(4, 3, 3, 2)\n",
        "x_pad = zero_pad(x, 2)\n",
        "print (\"x.shape =\\n\", x.shape)\n",
        "print (\"x_pad.shape =\\n\", x_pad.shape)\n",
        "print (\"x[1,1] =\\n\", x[1,1])\n",
        "print (\"x_pad[1,1] =\\n\", x_pad[1,1])\n",
        "\n",
        "fig, axarr = plt.subplots(1, 2)\n",
        "axarr[0].set_title('x')\n",
        "axarr[0].imshow(x[0,:,:,0])\n",
        "axarr[1].set_title('x_pad')\n",
        "axarr[1].imshow(x_pad[0,:,:,0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape =\n",
            " (4, 3, 3, 2)\n",
            "x_pad.shape =\n",
            " (4, 7, 7, 2)\n",
            "x[1,1] =\n",
            " [[ 0.90085595 -0.68372786]\n",
            " [-0.12289023 -0.93576943]\n",
            " [-0.26788808  0.53035547]]\n",
            "x_pad[1,1] =\n",
            " [[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb247d2ba90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_aNaTTwfMnx"
      },
      "source": [
        "**Salida Esperada**:\n",
        "\n",
        "```\n",
        "x.shape =\n",
        " (4, 3, 3, 2)\n",
        "x_pad.shape =\n",
        " (4, 7, 7, 2)\n",
        "x[1,1] =\n",
        " [[ 0.90085595 -0.68372786]\n",
        " [-0.12289023 -0.93576943]\n",
        " [-0.26788808  0.53035547]]\n",
        "x_pad[1,1] =\n",
        " [[ 0.  0.]\n",
        " [ 0.  0.]\n",
        " [ 0.  0.]\n",
        " [ 0.  0.]\n",
        " [ 0.  0.]\n",
        " [ 0.  0.]\n",
        " [ 0.  0.]]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SlYlWUSfMnx"
      },
      "source": [
        "### 3.2 - Un paso de convolución\n",
        "\n",
        "Es esta parte vamos a implementamos un paso de convolución, en el cual aplicamos un filtro a una sola posición de la entrada. Esto va a ser utilizado para construir una unidad convolucional, que:\n",
        "\n",
        "- Recibe un volumen de entrada\n",
        "- Aplica un filtro a cada posición de la entrada\n",
        "- Devuelve otro volumen\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1lD-xJ-dqyO4CmXBDN4Xnb-wwVb3n5fsd\" style=\"width:500px;height:300px;\">\n",
        "<caption><center> <u> <font color='white'> **Figura 2** </u><font color='white'> : **Operación de convolución** <br> con filtro de 3x3 y una stride de 1 </center></caption>\n",
        "\n",
        "En una aplicación de visión por computador, cada valor en la matriz de la izquierda corresponde a un solo pixel, y convolucionamos un filtro de 3x3 con la imagen multiplicando sus valores elemento a elemento con la matriz original, sumándolos y agregando un bias. En la primera parte del ejercicio hay que implementar un paso simple de la convolución, correspondiendo a aplicar un filtro a una sola de las posicionas para obtener un solo valor de salida.\n",
        "    \n",
        "Luego vamos a implementar una función que aplica la función de más arriba a múltiples posiciones de la entrada para obtener la operación convolucional completa.\n",
        "    \n",
        "**Ejercicio**: Implementar conv_single_step(). [Tip](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.sum.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4ZULpCvfMny"
      },
      "source": [
        "**Obs.**: La variable b se pasa como un array de numpy. Si agregamos un valor escalar (un float o un entero) a un array numpy, el resultado es un array. En el caso especial en que el array de numpy contiene un solo valor, podemos castearlo a float para convertirlo a un valor escalar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6ajzDuDfMny"
      },
      "source": [
        "def conv_single_step(a_slice_prev, W, b):\n",
        "    \"\"\"\n",
        "    Aplicar un filtro definido por parámetros W a una sola slice (a_slice_prev) de una salida de activaciones de una capa\n",
        "    anterior.\n",
        "    \n",
        "    Argumentos:\n",
        "    a_slice_prev -- Slice de datos de entrada de dimensiones (f, f, n_C_prev)\n",
        "    W -- Pesos del filtro con dimensiones (f, f, n_C_prev)\n",
        "    b -- Parámetros de bias representados por una matriz de dimensiones (1, 1, 1)\n",
        "    \n",
        "    Returna:\n",
        "    Z -- un valor escalar, resultado de convolucionar la ventana (W, b) que se desplaza sobre un sub-rectángulo x de\n",
        "         los datos de entrada\n",
        "    \"\"\"\n",
        "\n",
        "    ### Comienzo del código ### (≈ 2 líneas de código)\n",
        "    # Producto elemento a elemento entre a_slice_prev y W, NO sumar el bias aún\n",
        "    s =  a_slice_prev * W\n",
        "    # Suma sobre todas los elementos del volumen s\n",
        "    Z = np.sum(s)\n",
        "    # Sumar b a Z. Castear b a un float() de manera que Z resulta en un valor escalar\n",
        "    Z = float(Z + b)\n",
        "    ### Fin del código ###\n",
        "\n",
        "    return Z"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "N6FSIohhfMn1",
        "outputId": "3fc4471c-4c63-405c-d6ad-af35e7e19131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "a_slice_prev = np.random.randn(4, 4, 3)\n",
        "W = np.random.randn(4, 4, 3)\n",
        "b = np.random.randn(1, 1, 1)\n",
        "\n",
        "Z = conv_single_step(a_slice_prev, W, b)\n",
        "print(\"Z =\", Z)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z = -6.999089450680221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BODLTJB5fMn3"
      },
      "source": [
        "**Salida Esperada**:\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            **Z**\n",
        "        </td>\n",
        "        <td>\n",
        "            -6.99908945068\n",
        "        </td>\n",
        "    </tr>\n",
        "\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8DogGzjfMn4"
      },
      "source": [
        "### 3.3 - Redes Neuronales Convolucionales - Forward pass\n",
        "\n",
        "En el forward pass tomamos varios filtros y los convolucionamos con la entrada. Cada convolución devuelve como resultado una matriz 2D. Esas matrices se apilan para obtener un volumen 3D:\n",
        "\n",
        "<center>\n",
        "<img width=\"620\" height=\"440\" src=\"https://drive.google.com/uc?export=view&id=1jKGVfDT5gi3g7xCp1tnZhMAOpK10LQGJ\">\n",
        "</center>\n",
        "\n",
        "\n",
        "**Ejercicio**: \n",
        "Implementar la función más abajo para convolucionar los filtros `W` con las activaciones de entrada `A_prev`.\n",
        "Esta funcion recibe las siguientes entradas:\n",
        "* `A_prev`, activaciones de salida de la capa anterior (para un batch de m entradas);\n",
        "* Los pesos de los filtros son denotados con `W`.  El tamaño del filtro es `f` por `f`.\n",
        "* Un vector de bias `b`, donde cada filtro tiene su propio valor escalar de bias.\n",
        "\n",
        "Finalmente también tiene acceso a un diccionario de hiperparámetros que contiene la `stride` (zancada) y el `padding` (relleno).\n",
        "\n",
        "**Tip**: \n",
        "1. Para seleccionar una slice de 2x2 de la esquina superior izquierda de una matriz \"a_prev\" (dimensiones (5,5,3)) se puede hacer:\n",
        "```python\n",
        "a_slice_prev = a_prev[0:2,0:2,:]\n",
        "```\n",
        "Notar como esto resulta en una matriz 3D que tiene altura 2, ancho 2 y profundidad 3. La profundidad es el número de canales.\n",
        "Esto va aser útil cuando definamos `a_slice_prev` más abajo, usando los índices `start/end` qye vamos a definir.\n",
        "\n",
        "2. Para definir a_slice hay que primero definir sus esquinar `vert_start`, `vert_end`, `horiz_start` y `horiz_end`.\n",
        "Esta figura puede ser útil para determinar cómo cada esquina puede ser definida usando h, w, f y s en el código de abajo.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1KjAJXzfUToZHu5MEMlZYclxiMkrDw0MB\" style=\"width:400px;height:300px;\">\n",
        "<caption><center> <u> <font color='white'> **Figure 3** </u><font color='white'>  : **Definición de una slice usando definiciones verticales y horizontales de comienzo/fin (con un filtro de 2x2)** <br> Esta figura muestra sólo un canal.  </center></caption>\n",
        "\n",
        "\n",
        "**Recordar**:\n",
        "Las fórmulas relacionadas con las dimensiones de salida de la convolución con la dimensión de la entrada son: \n",
        "    \n",
        "$$ n_H = \\lfloor \\frac{n_{H_{prev}} - f + 2 \\times pad}{stride} \\rfloor +1 $$\n",
        "$$ n_W = \\lfloor \\frac{n_{W_{prev}} - f + 2 \\times pad}{stride} \\rfloor +1 $$\n",
        "$$ n_C = \\text{cantidad de filtros usados en la convolucion}$$\n",
        "\n",
        "Para este ejercicio no es necesario vectorizar y se puede implementar todo con bucles for."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmH99vHAfMn5"
      },
      "source": [
        "#### Tips adicionales si es muy difícil\n",
        "\n",
        "* Usar subselección (slicing) de un array (e.g.`variable[0:1,:,3:5]`) para las siguientes variables:\n",
        "  `a_prev_pad` ,`W`, `b`  \n",
        "  Copiar parte del código y correrlo fuera de la función, en celdas separadas. \n",
        "  Chequear que el sub-array de cada array tiene las dimensiones esperadas.\n",
        "  \n",
        "* Para decidir cómo obtener vert_start, vert_end; horiz_start, horiz_end, recordar que todos son índices de capas previas. Dibujar un ejemplo con la capa previa rellenada con ceros (8x8, por ejemplo), y la capa actual (capa de salida) (2x2, por ejemplo).\n",
        "  \n",
        "  Los índices de la capa de salida están denotados por `h` y `w`.  \n",
        "* Asegurarse de que `a_slice_prev` tiene altura, ancho y profundidad.\n",
        "* Recordar que `a_prev_pad` es un subconjunto de `A_prev_pad`.  \n",
        "  Pensar acerca de cuál debe ser usado dentro de los bucles for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "3iOAwcvrfMn6"
      },
      "source": [
        "def conv_forward(A_prev, W, b, hparameters):\n",
        "    \"\"\"\n",
        "    Implementa un forward pass de una función de convolución\n",
        "    \n",
        "    \n",
        "    Argumentos:\n",
        "    A_prev -- activaciones de salida de una capa anterior, \n",
        "        array de numpy de dimensiones (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    W -- Pesos de los filtros, array de numpy de tamaño (f, f, n_C_prev, n_C)\n",
        "    b -- Vector de bias, array de numpy de tamaño (1, 1, 1, n_C)\n",
        "    hparameters -- diccionario de python conteniendo \"stride\" y \"pad\"\n",
        "        \n",
        "    Retorna:\n",
        "    Z -- salidad de la convolución, array de numpy de dimensiones (m, n_H, n_W, n_C)\n",
        "    cache -- valores que son necesarios en el caso de implementar una función conv_backward() para el backward pass\n",
        "    \"\"\"\n",
        "    \n",
        "    ### Comienzo del código ###\n",
        "    # Recuperar las dimensiones de A_prev\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = np.shape(A_prev)\n",
        "    \n",
        "    # Recuperar las dimensiones de W\n",
        "    (f, f, n_C_prev, n_C) = np.shape(W)\n",
        "    \n",
        "    # Recuperar la información de los hparameters\n",
        "    stride = hparameters['stride']\n",
        "    pad = hparameters['pad']\n",
        "    \n",
        "    # Computar las dimensines del volumen de salida CONV usando la fórmula dada más arriba\n",
        "    # Tip: usar int() para aplicar la operación 'floor'.\n",
        "    n_H = int((n_H_prev - f + 2 * pad) / stride) + 1\n",
        "    n_W = int((n_W_prev - f + 2 * pad) / stride) + 1\n",
        "    \n",
        "    # Inicializar el volumen de salida Z con ceros.\n",
        "    Z = np.zeros((m, n_H, n_W, n_C))\n",
        "    \n",
        "    # Crear un A_prev_pad rellenando con ceros los bordes de A_prev\n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    \n",
        "    for i in range(m):               # iterar a través del batch de ejemplos\n",
        "        a_prev_pad = A_prev_pad[i,:,:,:] # seleccionar el ejemplo i-ésimo de la activación rellenada con ceros\n",
        "        for h in range(n_H):           # iterar sobre el eje vertical del volumen de salida\n",
        "            # Encontrar el comienzo y fin verticales de la \"slice\" actual\n",
        "            vert_start = h * stride\n",
        "            vert_end = h * stride+ f\n",
        "            \n",
        "            for w in range(n_W):       # iterar sobre el eje horizontal del volumen de salida\n",
        "                # Encontrar el comienzo y fin en el eje horizontal de la \"slice\" actual\n",
        "                horiz_start = w * stride\n",
        "                horiz_end = w * stride + f\n",
        "                \n",
        "                for c in range(n_C):   # iterar sobre los canales (# de filtros) del volumen de salida\n",
        "                                        \n",
        "                    # Usar las esquinas halladas para definir una slice 3D de a_prev_pad\n",
        "                    a_slice_prev = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n",
        "                    \n",
        "                    # Convolucionar la slice 3D con el filtro correcto en W y el bias b\n",
        "                    # para obtener la salida de una 'neurona'\n",
        "                    weights = W\n",
        "                    biases = b\n",
        "                    Z[i, h, w, c] = conv_single_step(a_slice_prev,W[:,:,:,c], b[:,:,:,c])\n",
        "                                        \n",
        "    ### Fin del código ###\n",
        "    \n",
        "    # Verificar que el volumen de salida tiene las dimensiones correctas\n",
        "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
        "    \n",
        "    # Guardar la info en \"cache\" para el paso de backprop \n",
        "    cache = (A_prev, W, b, hparameters)\n",
        "    \n",
        "    return Z, cache"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "960RBnZofMn8",
        "outputId": "7d175140-f25f-4bc1-8e92-520c668016ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(10,5,7,4)\n",
        "W = np.random.randn(3,3,4,8)\n",
        "b = np.random.randn(1,1,1,8)\n",
        "hparameters = {\"pad\" : 1,\n",
        "               \"stride\": 2}\n",
        "\n",
        "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
        "print(\"Z's mean =\\n\", np.mean(Z))\n",
        "print(\"Z[3,2,1] =\\n\", Z[3,2,1])\n",
        "print(\"cache_conv[0][1][2][3] =\\n\", cache_conv[0][1][2][3])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z's mean =\n",
            " 0.6923608807576933\n",
            "Z[3,2,1] =\n",
            " [-1.28912231  2.27650251  6.61941931  0.95527176  8.25132576  2.31329639\n",
            " 13.00689405  2.34576051]\n",
            "cache_conv[0][1][2][3] =\n",
            " [-1.1191154   1.9560789  -0.3264995  -1.34267579]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RgQ8nuCfMn_"
      },
      "source": [
        "**Salida esperada**:\n",
        "```\n",
        "Z's mean =\n",
        " 0.692360880758\n",
        "Z[3,2,1] =\n",
        " [ -1.28912231   2.27650251   6.61941931   0.95527176   8.25132576\n",
        "   2.31329639  13.00689405   2.34576051]\n",
        "cache_conv[0][1][2][3] = [-1.1191154   1.9560789  -0.3264995  -1.34267579]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItvcPCbefMn_"
      },
      "source": [
        "Finalmente, la capa CONV debe también aplicar una función de activación, en cuyo caso habría que agregar el siguiente código:\n",
        "\n",
        "```python\n",
        "# Convolucionar el sub-rectángulo para obtener el valor de la neurona de salida\n",
        "Z[i, h, w, c] = ...\n",
        "# Aplicar la función de activación\n",
        "A[i, h, w, c] = activation(Z[i, h, w, c])\n",
        "```\n",
        "\n",
        "Este paso no lo hacemos en este ejercicio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI8x94njfMoA"
      },
      "source": [
        "## 4 - Pooling layer \n",
        "\n",
        "La capa de pooling (POOL) reduce la altura y el ancho de la entrada. Ayuda a reducir costos de cómputo y hace los detectores de features más invariantes a su posición dentro de la entrada. Hay dos tipos de capas `pooling`:\n",
        "\n",
        "- Capa Max-pooling: desplaza una ventana ($f, f$) sobre la entrada y guarda el valor máximo que observa la ventana en la salida.\n",
        "\n",
        "- Capa Average-pooling: desplaza una ventana ($f, f$) sobre la entrada y guarda el valor promedio de la ventana en la salida.\n",
        "\n",
        "<table>\n",
        "<td>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1CfBogHLuT6TtChS5rEb6iHeI_6AyKIoT\" style=\"width:500px;height:300px;\">\n",
        "<td>\n",
        "\n",
        "<td>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Ou7jpZ4G-DbFd6_xwFLQlZKq-VlL0aJY\" style=\"width:500px;height:300px;\">\n",
        "<td>\n",
        "</table>\n",
        "\n",
        "Estas capas de polling no tienen parámetros para entrener en el paso de backprop. De todas maneras tienen hiperparámetros como el tamaño de la ventana $f$. Esto especifica la altura y el ancho de la ventana sobre la cual se computa el máximo o el promedio.\n",
        "\n",
        "### 4.1 - Pooling en la dirección forward\n",
        "Vamos a implementar MAX-POOL y AVG-POOL en la misma función.\n",
        "\n",
        "**Ejercicio**: Implementar el forward pass de la capa de pooling. Hay algunos tips en el código a completar abajo.\n",
        "\n",
        "**Recordar**:\n",
        "Como no hay padding (relleno con ceros), las fórmulas que relacionan las dimensiones de la capa de salidad con las de la capa de entrada son:\n",
        "\n",
        "$$ n_H = \\lfloor \\frac{n_{H_{prev}} - f}{stride} \\rfloor +1 $$\n",
        "\n",
        "$$ n_W = \\lfloor \\frac{n_{W_{prev}} - f}{stride} \\rfloor +1 $$\n",
        "\n",
        "$$ n_C = n_{C_{prev}}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "BR2Zo6MWfMoA"
      },
      "source": [
        "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
        "    \"\"\"\n",
        "    Implementa el forward pass de la capa pooling\n",
        "    \n",
        "    Argumentos:\n",
        "    A_prev -- Data de entrada, array de numpy con dimensiones (m, n_H_prev, n_W_prev, n_C_prev).\n",
        "    hparameters -- diccionario de python conteniendo \"f\" y \"stride\".\n",
        "    mode -- El tipo de pooling a utilizar, definido con una string (\"max\" o \"average\")\n",
        "    \n",
        "    Retorna:\n",
        "    A -- salida de la capa de pooling, un array de numpy con dimensiones (m, n_H, n_W, n_C)\n",
        "    cache -- cache de información devuelta en el backward pass de la capa de pooling, contiene parámetros de entrada\n",
        "             y hparameter\n",
        "    \"\"\"\n",
        "    \n",
        "    # Recuperar las dimensiones de la entrada\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    # Recuperar hiperparámetros de \"hparameters\"\n",
        "    f = hparameters[\"f\"]\n",
        "    stride = hparameters[\"stride\"]\n",
        "    \n",
        "    # Definir dimensiones de la salida\n",
        "    n_H = int(1 + (n_H_prev - f) / stride)\n",
        "    n_W = int(1 + (n_W_prev - f) / stride)\n",
        "    n_C = n_C_prev\n",
        "    \n",
        "    # Inicializar la matriz A\n",
        "    A = np.zeros((m, n_H, n_W, n_C))              \n",
        "    \n",
        "    ### Comienzo del código ###\n",
        "    for i in range(m):                         # iterar sobre los ejemplos de entrenamiento\n",
        "        for h in range(n_H):                     # iterar sobre el eje vertical del volumen de salida\n",
        "            # encontrar los índices de inicio y fin de la \"slice actual\"\n",
        "            vert_start = h * stride\n",
        "            vert_end =  h * stride+ f\n",
        "            \n",
        "            for w in range(n_W):                 # iterar sobre el eje horizontal del salida \n",
        "                # encontrar los índices inicial y final en la dimensión vertical \n",
        "                # dentro de la \"slice\" actual                \n",
        "                horiz_start =  w * stride\n",
        "                horiz_end =  w * stride + f\n",
        "                \n",
        "                for c in range (n_C):            # iterar sobre los canales del volumen de salida\n",
        "                    \n",
        "                    # usar los índices obtenidos para definir la slice actual en el\n",
        "                    # iésimo ejemplo de A_prev, para el canal c.\n",
        "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end,c]\n",
        "                    \n",
        "                    # Computer la operación de pooling en la slice.\n",
        "                    # El if sirve para diferenciar los tipos de pooling (max o average)\n",
        "                    # Tip: usar np.max and np.mean para el caso correspondiente\n",
        "                    if mode == \"max\":\n",
        "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
        "                    elif mode == \"average\":\n",
        "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
        "    \n",
        "    ### Fin del código a completar ###\n",
        "    \n",
        "    # Guardar la entrada y los hparameters en el \"cache\" para el backward pass\n",
        "    cache = (A_prev, hparameters)\n",
        "    \n",
        "    # Asegurarse de que la salida tiene las dimensiones correctas\n",
        "    assert(A.shape == (m, n_H, n_W, n_C))\n",
        "    \n",
        "    return A, cache"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "ZklIvHo1fMoD",
        "outputId": "a6b2f7a5-e282-47a3-c9b7-cac08f05e854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        }
      },
      "source": [
        "# Caso 1: stride de valor 1\n",
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(2, 5, 5, 3)\n",
        "hparameters = {\"stride\" : 1, \"f\": 3}\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters)\n",
        "print(\"mode = max\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A =\\n\", A)\n",
        "print()\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A =\\n\", A)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mode = max\n",
            "A.shape = (2, 3, 3, 3)\n",
            "A =\n",
            " [[[[1.74481176 0.90159072 1.65980218]\n",
            "   [1.74481176 1.46210794 1.65980218]\n",
            "   [1.74481176 1.6924546  1.65980218]]\n",
            "\n",
            "  [[1.14472371 0.90159072 2.10025514]\n",
            "   [1.14472371 0.90159072 1.65980218]\n",
            "   [1.14472371 1.6924546  1.65980218]]\n",
            "\n",
            "  [[1.13162939 1.51981682 2.18557541]\n",
            "   [1.13162939 1.51981682 2.18557541]\n",
            "   [1.13162939 1.6924546  2.18557541]]]\n",
            "\n",
            "\n",
            " [[[1.19891788 0.84616065 0.82797464]\n",
            "   [0.69803203 0.84616065 1.2245077 ]\n",
            "   [0.69803203 1.12141771 1.2245077 ]]\n",
            "\n",
            "  [[1.96710175 0.84616065 1.27375593]\n",
            "   [1.96710175 0.84616065 1.23616403]\n",
            "   [1.62765075 1.12141771 1.2245077 ]]\n",
            "\n",
            "  [[1.96710175 0.86888616 1.27375593]\n",
            "   [1.96710175 0.86888616 1.23616403]\n",
            "   [1.62765075 1.12141771 0.79280687]]]]\n",
            "\n",
            "mode = average\n",
            "A.shape = (2, 3, 3, 3)\n",
            "A =\n",
            " [[[[-3.01046719e-02 -3.24021315e-03 -3.36298859e-01]\n",
            "   [ 1.43310483e-01  1.93146751e-01 -4.44905196e-01]\n",
            "   [ 1.28934436e-01  2.22428468e-01  1.25067597e-01]]\n",
            "\n",
            "  [[-3.81801899e-01  1.59993515e-02  1.70562706e-01]\n",
            "   [ 4.73707165e-02  2.59244658e-02  9.20338402e-02]\n",
            "   [ 3.97048605e-02  1.57189094e-01  3.45302489e-01]]\n",
            "\n",
            "  [[-3.82680519e-01  2.32579951e-01  6.25997903e-01]\n",
            "   [-2.47157416e-01 -3.48524998e-04  3.50539717e-01]\n",
            "   [-9.52551510e-02  2.68511000e-01  4.66056368e-01]]]\n",
            "\n",
            "\n",
            " [[[-1.73134159e-01  3.23771981e-01 -3.43175716e-01]\n",
            "   [ 3.80634669e-02  7.26706274e-02 -2.30268958e-01]\n",
            "   [ 2.03009393e-02  1.41414785e-01 -1.23158476e-02]]\n",
            "\n",
            "  [[ 4.44976963e-01 -2.61694592e-03 -3.10403073e-01]\n",
            "   [ 5.08114737e-01 -2.34937338e-01 -2.39611830e-01]\n",
            "   [ 1.18726772e-01  1.72552294e-01 -2.21121966e-01]]\n",
            "\n",
            "  [[ 4.29449255e-01  8.44699612e-02 -2.72909051e-01]\n",
            "   [ 6.76351685e-01 -1.20138225e-01 -2.44076712e-01]\n",
            "   [ 1.50774518e-01  2.89111751e-01  1.23238536e-03]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIMyQkgEfMoF"
      },
      "source": [
        "** Salida esperada**\n",
        "```\n",
        "mode = max\n",
        "A.shape = (2, 3, 3, 3)\n",
        "A =\n",
        " [[[[ 1.74481176  0.90159072  1.65980218]\n",
        "   [ 1.74481176  1.46210794  1.65980218]\n",
        "   [ 1.74481176  1.6924546   1.65980218]]\n",
        "\n",
        "  [[ 1.14472371  0.90159072  2.10025514]\n",
        "   [ 1.14472371  0.90159072  1.65980218]\n",
        "   [ 1.14472371  1.6924546   1.65980218]]\n",
        "\n",
        "  [[ 1.13162939  1.51981682  2.18557541]\n",
        "   [ 1.13162939  1.51981682  2.18557541]\n",
        "   [ 1.13162939  1.6924546   2.18557541]]]\n",
        "\n",
        "\n",
        " [[[ 1.19891788  0.84616065  0.82797464]\n",
        "   [ 0.69803203  0.84616065  1.2245077 ]\n",
        "   [ 0.69803203  1.12141771  1.2245077 ]]\n",
        "\n",
        "  [[ 1.96710175  0.84616065  1.27375593]\n",
        "   [ 1.96710175  0.84616065  1.23616403]\n",
        "   [ 1.62765075  1.12141771  1.2245077 ]]\n",
        "\n",
        "  [[ 1.96710175  0.86888616  1.27375593]\n",
        "   [ 1.96710175  0.86888616  1.23616403]\n",
        "   [ 1.62765075  1.12141771  0.79280687]]]]\n",
        "\n",
        "mode = average\n",
        "A.shape = (2, 3, 3, 3)\n",
        "A =\n",
        " [[[[ -3.01046719e-02  -3.24021315e-03  -3.36298859e-01]\n",
        "   [  1.43310483e-01   1.93146751e-01  -4.44905196e-01]\n",
        "   [  1.28934436e-01   2.22428468e-01   1.25067597e-01]]\n",
        "\n",
        "  [[ -3.81801899e-01   1.59993515e-02   1.70562706e-01]\n",
        "   [  4.73707165e-02   2.59244658e-02   9.20338402e-02]\n",
        "   [  3.97048605e-02   1.57189094e-01   3.45302489e-01]]\n",
        "\n",
        "  [[ -3.82680519e-01   2.32579951e-01   6.25997903e-01]\n",
        "   [ -2.47157416e-01  -3.48524998e-04   3.50539717e-01]\n",
        "   [ -9.52551510e-02   2.68511000e-01   4.66056368e-01]]]\n",
        "\n",
        "\n",
        " [[[ -1.73134159e-01   3.23771981e-01  -3.43175716e-01]\n",
        "   [  3.80634669e-02   7.26706274e-02  -2.30268958e-01]\n",
        "   [  2.03009393e-02   1.41414785e-01  -1.23158476e-02]]\n",
        "\n",
        "  [[  4.44976963e-01  -2.61694592e-03  -3.10403073e-01]\n",
        "   [  5.08114737e-01  -2.34937338e-01  -2.39611830e-01]\n",
        "   [  1.18726772e-01   1.72552294e-01  -2.21121966e-01]]\n",
        "\n",
        "  [[  4.29449255e-01   8.44699612e-02  -2.72909051e-01]\n",
        "   [  6.76351685e-01  -1.20138225e-01  -2.44076712e-01]\n",
        "   [  1.50774518e-01   2.89111751e-01   1.23238536e-03]]]]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "mxVAPpfBfMoG",
        "outputId": "454227c4-9843-4ad6-a6e4-cefb69567645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# Caso 2: stride de valor 2\n",
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(2, 5, 5, 3)\n",
        "hparameters = {\"stride\" : 2, \"f\": 3}\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters)\n",
        "print(\"mode = max\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A =\\n\", A)\n",
        "print()\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A =\\n\", A)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mode = max\n",
            "A.shape = (2, 2, 2, 3)\n",
            "A =\n",
            " [[[[1.74481176 0.90159072 1.65980218]\n",
            "   [1.74481176 1.6924546  1.65980218]]\n",
            "\n",
            "  [[1.13162939 1.51981682 2.18557541]\n",
            "   [1.13162939 1.6924546  2.18557541]]]\n",
            "\n",
            "\n",
            " [[[1.19891788 0.84616065 0.82797464]\n",
            "   [0.69803203 1.12141771 1.2245077 ]]\n",
            "\n",
            "  [[1.96710175 0.86888616 1.27375593]\n",
            "   [1.62765075 1.12141771 0.79280687]]]]\n",
            "\n",
            "mode = average\n",
            "A.shape = (2, 2, 2, 3)\n",
            "A =\n",
            " [[[[-0.03010467 -0.00324021 -0.33629886]\n",
            "   [ 0.12893444  0.22242847  0.1250676 ]]\n",
            "\n",
            "  [[-0.38268052  0.23257995  0.6259979 ]\n",
            "   [-0.09525515  0.268511    0.46605637]]]\n",
            "\n",
            "\n",
            " [[[-0.17313416  0.32377198 -0.34317572]\n",
            "   [ 0.02030094  0.14141479 -0.01231585]]\n",
            "\n",
            "  [[ 0.42944926  0.08446996 -0.27290905]\n",
            "   [ 0.15077452  0.28911175  0.00123239]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EOY8zeIfMoJ"
      },
      "source": [
        "**Salida esperada:**\n",
        "    \n",
        "```\n",
        "mode = max\n",
        "A.shape = (2, 2, 2, 3)\n",
        "A =\n",
        " [[[[ 1.74481176  0.90159072  1.65980218]\n",
        "   [ 1.74481176  1.6924546   1.65980218]]\n",
        "\n",
        "  [[ 1.13162939  1.51981682  2.18557541]\n",
        "   [ 1.13162939  1.6924546   2.18557541]]]\n",
        "\n",
        "\n",
        " [[[ 1.19891788  0.84616065  0.82797464]\n",
        "   [ 0.69803203  1.12141771  1.2245077 ]]\n",
        "\n",
        "  [[ 1.96710175  0.86888616  1.27375593]\n",
        "   [ 1.62765075  1.12141771  0.79280687]]]]\n",
        "\n",
        "mode = average\n",
        "A.shape = (2, 2, 2, 3)\n",
        "A =\n",
        " [[[[-0.03010467 -0.00324021 -0.33629886]\n",
        "   [ 0.12893444  0.22242847  0.1250676 ]]\n",
        "\n",
        "  [[-0.38268052  0.23257995  0.6259979 ]\n",
        "   [-0.09525515  0.268511    0.46605637]]]\n",
        "\n",
        "\n",
        " [[[-0.17313416  0.32377198 -0.34317572]\n",
        "   [ 0.02030094  0.14141479 -0.01231585]]\n",
        "\n",
        "  [[ 0.42944926  0.08446996 -0.27290905]\n",
        "   [ 0.15077452  0.28911175  0.00123239]]]]\n",
        "```"
      ]
    }
  ]
}