{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios resueltos de clase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 1\n",
    "\n",
    "Obtener para cada fila en X, el índice de la fila en C con distancia euclídea más pequeña.\n",
    "Es decir, decir para cada fila en X a qué cluster pertenece en C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 1\n",
    "def get_distances(X, C):\n",
    "    \"\"\"Obtiene para cada vector de X la distancia a cada vector de C.\n",
    "    X -- Array. Cada fila es un vector\n",
    "    C -- Array. Cada fila es un vector\n",
    "    \"\"\"\n",
    "   \n",
    "    \"\"\"\n",
    "    Ignorando el cuadrado y raíz por el momento, quiero calcular distances = X - C, tal que:\n",
    "\n",
    "        ~~~\n",
    "        D = [\n",
    "            X[0] - C[0],\n",
    "            X[0] - C[1],\n",
    "            X[1] - C[0],\n",
    "            X[1] - C[1],\n",
    "            X[2] - C[0],\n",
    "            X[2] - C[1]\n",
    "        ]\n",
    "        ~~~\n",
    "\n",
    "        siendo:\n",
    "\n",
    "        ~~~\n",
    "            X[0] - C[0] = [1,2,3] - [1,0,0] = [0,-2,3],\n",
    "            X[0] - C[1] = [1,2,3] - [1,0,0] = [0,2,3],\n",
    "            ...\n",
    "        ~~~\n",
    "        \n",
    "    Según https://scipy.github.io/old-wiki/pages/EricsBroadcastingDoc:\n",
    "    \n",
    "    > In order to broadcast, the size of the trailing axes for both arrays \n",
    "    > in an operation must either be the same size or one of them must be one.\n",
    "\n",
    "    Si intento restar directamente (3,3) - (2,3) Falla la regla de broadcast porque 3!=2\n",
    "    y ninguno de los dos es 1.\n",
    "    Pero si en cambio pruebo con (3,3)-(2,1,3) la regla de broadcasting permite calcular\n",
    "    (1,3)-(1,3) sobre el eje 0 (filas):\n",
    "        Operation Axis (0) Size       Trailing Axis Size\n",
    "        3                            (3) automatically reshaped to (1,3)\n",
    "        2                            (1,3)\n",
    "        \n",
    "    Nota: interpreto que es el (1,3) de dimensión 2 el que lleva a expandir el (3) a (1,3).\n",
    "    \"\"\"\n",
    "    expanded_C = C[:, None]\n",
    "    return np.sqrt(np.sum((expanded_C - X) ** 2, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 1 - Test\n",
    "\n",
    "X = np.array([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "])\n",
    "C = np.array([\n",
    "    [1,0,0],\n",
    "    [0,1,1]\n",
    "])\n",
    "distances = get_distances(X,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2\n",
    "\n",
    "Obtener para cada fila en X, el índice de la fila en C con distancia euclídea más pequeña.\n",
    "Es decir, decir para cada fila en X a qué cluster pertenece en C.\n",
    "Por ejemplo, si el resultado anterior fue:\n",
    "\n",
    "~~~python\n",
    "[[ 3.60555128 8.36660027 13.45362405]\n",
    "[ 2.44948974 7.54983444 12.72792206]]\n",
    "~~~\n",
    "\n",
    "El programa debería devolver [1, 1, 1]\n",
    "Hint: utilizar np.argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 2 - Test\n",
    "def get_nearest(distances):\n",
    "    return np.argmin(distances,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest = get_nearest(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 3\n",
    "\n",
    "K-means es uno de los algoritmos más básicos en Machine Learning no supervisado.\n",
    "Es un algoritmo de clusterización, que agrupa los datos que comparten características similares.\n",
    "Recordemos que entendemos datos como n realizaciones del vector aleatorio X.\n",
    "El algoritmo K-means funcione de la siguiente manera:\n",
    "1. El usuario selecciona la cantidad de clusters a crear (n).\n",
    "2. Se seleccionan n elementos aleatorios de X como posiciones iniciales del los centroides C.\n",
    "3. Se calcula la distancia entre todos los puntos en X y todos los puntos en C.\n",
    "4. Para cada punto en X se selecciona el centroide más cercano de C.\n",
    "5. Se recalculan los centroides C a partir de usar las filas de X que pertenecen a cada centroide.\n",
    "6. Se itera entre 3 y 5 una cantidad fija de veces o hasta que la posición de los centroides no cambie.\n",
    "\n",
    "Implementar la función def k_means(X, n) de manera tal que al finalizar devuelva la posición de los\n",
    "centroides y a que cluster pertenece cada fila de X.\n",
    "Hint: para (2) utilizar funciones de np.random, para (3) y (4) usar los ejercicios anteriores,\n",
    "para (5) es válido utilizar un for. Iterar 10 veces entre (3) y (5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 3\n",
    "\n",
    "MAX_ITERATIONS = 10\n",
    "\n",
    "def k_means(X, n_clusters,max_iterations=MAX_ITERATIONS):\n",
    "    centroids = np.eye(n_clusters, X.shape[1])\n",
    "    #print(centroids)\n",
    "    for i in range(max_iterations):\n",
    "        #print(\"Iteration # {}\".format(i))\n",
    "        centroids, cluster_ids = k_means_loop(X, centroids)\n",
    "        #print(centroids)\n",
    "    return centroids, cluster_ids\n",
    "\n",
    "def k_means_loop(X, centroids):\n",
    "    # find labels for rows in X based in centroids values\n",
    "    expanded_centroids = centroids[:, None]\n",
    "    distances = np.sqrt(np.sum((expanded_centroids - X) ** 2, axis=2))\n",
    "    arg_min = np.argmin(distances, axis=0)\n",
    "    # recompute centroids\n",
    "    for i in range(centroids.shape[0]):\n",
    "        centroids[i] = np.mean(X[arg_min == i, :], axis=0)\n",
    "    return centroids, arg_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.19819746, -0.13760135, -0.42571892, -0.58473787],\n",
       "        [-0.15522857,  1.20505991, -0.30053494, -0.54552031],\n",
       "        [-0.53634651, -0.19557011,  1.30200757, -0.29674342],\n",
       "        [-0.28050539, -0.45120452, -0.20341983,  1.16346523]]),\n",
       " array([2, 0, 0, 2, 3, 2, 1, 1, 0, 2, 3, 0, 3, 1, 0, 1, 2, 3, 2, 2, 1, 2,\n",
       "        2, 1, 0, 0, 0, 2, 0, 1, 3, 2, 3, 3, 1, 3, 1, 0, 2, 3, 2, 2, 1, 2,\n",
       "        1, 0, 1, 3, 3, 2, 1, 2, 3, 0, 1, 3, 3, 1, 1, 3, 1, 0, 1, 0, 0, 1,\n",
       "        0, 2, 3, 0, 2, 0, 0, 3, 2, 1, 2, 2, 0, 3, 3, 2, 1, 2, 2, 1, 3, 0,\n",
       "        3, 3, 2, 0, 2, 1, 3, 1, 3, 2, 1, 0]))"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejercicio 3 - Test\n",
    "data, cluster_ids = build_cluster(100, 0.1)\n",
    "k_means(data,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 4\n",
    "\n",
    "Utilizar numpy para crear datos clusterizados A/B en 4 dimensiones.\n",
    "\n",
    "Hint:\n",
    "- Definir una matriz con centroides [1,0,0,0] y [0,1,0,0]\n",
    "- Utilizar una constante para separar o alejar los centroides entre si.\n",
    "- Utilizar np.repeat para crear n/2 muestras de cada centroide.\n",
    "- Sumar a cada centroide un vector aleatorio normal i.i.d. con media 0 y desvio (np.random.normal).\n",
    "- Armar un arreglo que tenga n enteros indicado si la muestra pertenece a A o a B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 4\n",
    "\n",
    "def build_cluster(n_samples, inv_overlap):\n",
    "    \"\"\"\n",
    "    Genera muestras pertenecientes a dos clusters.\n",
    "    n_samples -- Cantidad de muestras.\n",
    "    inv_overlap -- Distancia de separación.    \n",
    "    \"\"\"\n",
    "    centroids = np.array([\n",
    "        [1,0,0,0],\n",
    "        [0,1,0,0],\n",
    "    ], dtype=np.float32)\n",
    "    centroids = centroids * inv_overlap\n",
    "    data = np.repeat(centroids, n_samples / 2, axis=0)\n",
    "    normal_noise = np.random.normal(loc=0, scale=1, size=(n_samples, 4))\n",
    "    data = data + normal_noise\n",
    "    cluster_ids = np.array([[0],[1],])\n",
    "    cluster_ids = np.repeat(cluster_ids, n_samples / 2, axis=0)\n",
    "    return data, cluster_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.62308543, -1.68824715,  0.81403391,  0.30171272],\n",
       "       [ 3.09066407, -1.07279074,  0.81892817,  1.35063547],\n",
       "       [ 0.5081357 , -0.85738918, -0.31567735,  0.74435572],\n",
       "       [ 0.58544819,  0.99448112, -0.14850023,  0.61722938],\n",
       "       [ 0.0307204 , -0.93963297, -0.87267591,  0.74731429],\n",
       "       [ 1.77846486, -0.77867144, -0.25735863,  0.51235265],\n",
       "       [-0.51848566,  0.63949968,  0.51165927,  1.25882047],\n",
       "       [-0.20745672,  0.18819073, -0.97642459,  0.19596659],\n",
       "       [ 0.82171211,  2.9149364 ,  0.32300191, -0.81513456],\n",
       "       [ 0.68743125,  2.37736982, -0.68516705, -0.29264682]])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejercicio 4 - Test\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data, cluster_ids = build_cluster(10, 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 5\n",
    "\n",
    "Utilizar numpy para simular una exponencial de parámetro lambda.\n",
    "\n",
    "Hint:\n",
    "- Hacer una función que genere n muestras de la variable aleatoria X\n",
    "- Utilizar el resultado obtenido en la diapositiva anterior\n",
    "- Utilizar np.random.uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 5\n",
    "def exponential_random_variable(lambda_param, size):\n",
    "    u = np.random.uniform(low=0.0, high=1.0, size=size)\n",
    "    return (-1 / lambda_param) * np.log(1 - u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f0917dc0a90>"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejercicio 5 - Test\n",
    "\n",
    "data = exponential_random_variable(0.1,100)\n",
    "x = np.linspace(0,1,data.shape[0])\n",
    "plt.scatter(x,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 6\n",
    "\n",
    "Calcular la inversa generalizada y simular.\n",
    "Sabiendo que la variable aleatoria es continua, la función de densidad de probabilidad se define según:\n",
    "$$\n",
    "F_X(x) = P(X \\le x) = \\int_{-\\infty}^{x}f(t)dt\n",
    "$$\n",
    "\n",
    "Para una variable aleatoria con función de densidad de probabilidad:\n",
    "\n",
    "$$\n",
    "f_X(x) = 3x^2\\{0 < x < 1\\}\n",
    "$$\n",
    "\n",
    "Obtener la inversa generalizada y utilizar numpy para simular n muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 6 \n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 6 - Test\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 7\n",
    "\n",
    "Dado un dataset X de n muestras y m columnas, implementar un método en numpy para normalizar con\n",
    "z-score. \n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Pueden utilizar np.mean() y np.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 7\n",
    "def zscore_norm(dataset):\n",
    "    \"\"\" Normaliza un dataset c/ z-score\n",
    "    -- dataset: mxn, m=muestras,n=features\n",
    "    \"\"\"\n",
    "    feat_mean = np.mean(data,axis=0)   \n",
    "    feat_std = np.std(data,axis=0)\n",
    "    return (data-feat_mean)/feat_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.46316708, -0.71803103,  0.94394167, -1.43617745],\n",
       "       [ 1.69970919,  1.16303076,  0.39085843,  0.57723698],\n",
       "       [ 0.97845176, -1.21594742,  1.43547386, -0.16361972],\n",
       "       [ 0.85525387,  0.66969527, -1.39321191,  1.73830282],\n",
       "       [-0.69823896, -0.4212617 , -0.06382516, -1.17213775],\n",
       "       [-0.52202576, -1.89943673,  0.495294  ,  1.208384  ],\n",
       "       [-0.24990879,  1.07871132, -2.03155134, -0.5564533 ],\n",
       "       [-2.06481009,  1.0996945 , -0.11847228,  0.88458224],\n",
       "       [-0.31785593,  0.2135508 ,  0.67356055, -0.69199908],\n",
       "       [-0.14374236,  0.02999423, -0.33206782, -0.38811875]])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejercicio 7 - Test\n",
    "data, _ = build_cluster(10, 1)\n",
    "zscore_norm(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 8\n",
    "\n",
    "Siguiendo los pasos del slide anterior, se requiere utilizar numpy para calcular PCA del dataset de entrada X\n",
    "utilizando las 2 componentes más importantes.\n",
    "\n",
    "~~~python\n",
    "x = np.array(\n",
    "    [ \n",
    "        [0.4, 4800, 5.5], [0.7, 12104, 5.2], \n",
    "        [1, 12500, 5.5], [1.5, 7002, 4.0] \n",
    "    ])\n",
    "~~~\n",
    "Al finalizar la implementación en numpy corroborar obtener los mismos resultados que utilizando el código\n",
    "de la librería scikit-learn. Para comparar las matrices escribir un tests usando np.testing.assert_allclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 8\n",
    "def my_pca(x):\n",
    "    x2 = (x - x.mean(axis=0))\n",
    "    cov_1 = np.cov(x2.T)\n",
    "    w, v = np.linalg.eig(cov_1)\n",
    "    idx = w.argsort()[::-1]\n",
    "    w = w[idx]\n",
    "    v = v[:,idx]\n",
    "    return np.matmul(x2, v[:, :2])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2), (4, 3))"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejercicio 8 - Test\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x = np.array([ [0.4, 4800, 5.5], [0.7, 12104, 5.2], [1, 12500, 5.5], [1.5, 7002, 4.0] ])\n",
    "x_pca_mine = my_pca(x)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "x_std = StandardScaler(with_std=False).fit_transform(x)\n",
    "x_pca_sk = pca.fit_transform(x_std)\n",
    "\n",
    "x_pca_mine.shape, x_pca_sk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=1e-07, atol=0\n\n(shapes (4, 2), (4, 3) mismatch)\n x: array([[-4.301500e+03, -8.023262e-01],\n       [ 3.002500e+03, -1.289098e-01],\n       [ 3.398500e+03, -2.017142e-01],\n       [-2.099500e+03,  1.132950e+00]])\n y: array([[ 4.301500e+03, -8.023262e-01, -1.952083e-03],\n       [-3.002500e+03, -1.289098e-01,  2.066887e-01],\n       [-3.398500e+03, -2.017142e-01, -1.925836e-01],\n       [ 2.099500e+03,  1.132950e+00, -1.215309e-02]])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-344-a52477b8abb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx_pca_mine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pca_sk\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_allclose\u001b[0;34m(actual, desired, rtol, atol, equal_nan, err_msg, verbose)\u001b[0m\n\u001b[1;32m   1531\u001b[0m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Not equal to tolerance rtol=%g, atol=%g'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m     assert_array_compare(compare, actual, desired, err_msg=str(err_msg),\n\u001b[0;32m-> 1533\u001b[0;31m                          verbose=verbose, header=header, equal_nan=equal_nan)\n\u001b[0m\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    763\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0mflagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=1e-07, atol=0\n\n(shapes (4, 2), (4, 3) mismatch)\n x: array([[-4.301500e+03, -8.023262e-01],\n       [ 3.002500e+03, -1.289098e-01],\n       [ 3.398500e+03, -2.017142e-01],\n       [-2.099500e+03,  1.132950e+00]])\n y: array([[ 4.301500e+03, -8.023262e-01, -1.952083e-03],\n       [-3.002500e+03, -1.289098e-01,  2.066887e-01],\n       [-3.398500e+03, -2.017142e-01, -1.925836e-01],\n       [ 2.099500e+03,  1.132950e+00, -1.215309e-02]])"
     ]
    }
   ],
   "source": [
    "np.testing.assert_allclose( x_pca_mine, x_pca_sk )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 9\n",
    "\n",
    "Dato un dataset, hacer una funcion que utilizando numpy filtre las columnas y las filas que tienen NaNs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función helper para poblar dataset con NaNs\n",
    "def corrupt_dataset(dataset, percent,feat_range):   \n",
    "    \"\"\"Corrompe un dataset con NaNs\n",
    "        -- percent: porcentaje de 0=0%, 1=100% a corromper\n",
    "        -- feat_range: tupla con intervalo de columnas a corromper\n",
    "    \"\"\"\n",
    "    dataset_sz = dataset.shape[0]\n",
    "    dataset_feat = dataset.shape[1]\n",
    "    alt_row_indexes = np.random.randint(low=0, high=dataset_sz, size=int(dataset_sz*percent), dtype='l')  \n",
    "    alt_col_indexes = np.random.randint(\n",
    "        low=feat_range[0], \n",
    "        high=feat_range[1], \n",
    "        size=int(dataset_sz*percent), dtype='l')  \n",
    "    dataset[alt_row_indexes,alt_col_indexes] = None\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows_with_nan(corrupted_dataset):\n",
    "    \"\"\"Elimina filas que tengan NaNs\n",
    "    \"\"\"\n",
    "    return corrupted_dataset[np.all(np.isfinite(corrupted_dataset), axis=1)]\n",
    "\n",
    "def drop_cols_with_nan(corrupted_dataset):\n",
    "    \"\"\"Elimina columnas que tengan NaNs\n",
    "    \"\"\"\n",
    "    return corrupted_dataset[:,np.all(np.isfinite(corrupted_dataset), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 9 - Test\n",
    "dataset, _ =  build_cluster(10, 1)\n",
    "corrupted_dataset = corrupt_dataset(dataset, 0.4,(0,3))\n",
    "corrupted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rows_with_nan(corrupted_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, _ =  build_cluster(10, 1)\n",
    "corrupted_dataset = corrupt_dataset(dataset, 0.4,(0,2))\n",
    "corrupted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols_with_nan(corrupted_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 10 (TODO)\n",
    "\n",
    "Reemplazar NaNs por la media de la columna. Dato un dataset, hacer una función que utilizando numpy reemplace los NaNs por la media de la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 10\n",
    "def replace_nans_with_mean(dataset):\n",
    "    filtered_rows = drop_rows_with_nan(dataset)\n",
    "    col_avg = filtered_rows.mean(axis=0)\n",
    "    nan_mask = np.isnan(dataset)\n",
    "    dataset[nan_mask] = col_avg\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 10 - Test\n",
    "dataset, _ =  build_cluster(10, 1)\n",
    "corrupted_dataset = corrupt_dataset(dataset, 0.4,(0,2))\n",
    "corrupted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_nans_with_mean(corrupted_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_avg = filtered_rows.mean(axis=0)\n",
    "col_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nan_mask = np.isnan(corrupted_dataset)\n",
    "nan_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 11 \n",
    "\n",
    "Dado un dataset X separarlo en 70 / 20 / 10.\n",
    "\n",
    "Hint: A partir de utilizar np.random.permutation hacer un método que dado un dataset, devuelva los 3 datasets\n",
    "como nuevos numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 11\n",
    "def split_dataset(dataset, training=0.7, validation=0.2,testing=0.1):\n",
    "    \"\"\" Dado un dataset, lo particiona en training, validation y testing y devuelve estos tres arrays.\n",
    "    \"\"\"\n",
    "    dataset_sz = dataset.shape[0]\n",
    "    i0 = int(dataset_sz*training)\n",
    "    i1 = int(dataset_sz*(training+validation))\n",
    "    indices = np.random.permutation(dataset_sz)\n",
    "    training_idx, validation_idx, testing_idx = indices[0:i0], indices[i0:i1],indices[i1:]    \n",
    "    return dataset[training_idx], dataset[validation_idx], dataset[testing_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 11 - Test\n",
    "dataset, _ =  build_cluster(10, 1)\n",
    "split_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 12 (integrador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generar un dataset sintético que clusterice data en 4 clusters utilizando números random.\n",
    " - a. Utilizar 4 dimensiones.\n",
    " - b. Generar un dataset con 100K de muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 100000\n",
    "N_CLUSTERS = 4\n",
    "dataset,clusters = build_cluster(N_SAMPLES,N_CLUSTERS)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cambiar algunos puntos de manera aleatoria y agregar NaN (0.1% del dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_indexes = np.random.randint(low=0, high=N_SAMPLES-1, size=int(N_SAMPLES*0.1), dtype='l')\n",
    "alt_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(1,4)\n",
    "help(np.random.rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vector = np.random.rand(low=-1.0, high=1.0, size=4)\n",
    "random_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Guardar el dataset en un .pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Cargar el dataset con Numpy desde el .pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Completar NaN con la media de cada feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Calcular la norma l2, la media y el desvío de cada feature con funciones numpy vectorizadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Agregar una columna a partir de generar una variable aleatoria exponencial a todos los puntos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Hacer el histograma de la distribución exponencial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Aplicar PCA al dataset reduciendo a 2 dimensiones y graficar el cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Hacer la clusterización con el k-means desarrollado en clase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Volver a graficar el cluster con lo obtenido en (10) y comparar resultados con (9).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Analizar qué pasa si los clusters comienzan a tener overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
