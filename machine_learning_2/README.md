# Machine Learning 2

## Resumen de clases

### Clase 1. Jueves 29/10/2020. Optimización de Hiperparámetros

### Keypoints

- Notebook: 
- ¿Cómo elegimos los mejores hiperparámetros para nuestro problema?
  - ¿Qué es mejor? ¿Con respecto a exactitud? ¿Área bajo la curva ROC?
  - Paso 0. Definir métrica que quiero optimizar.
- Técnicas de selección de HPs.
  - Manual Search: la más rudimentaria (o sea, pruebo al azar). Cansador, tedioso y poco eficiente.
  - Grid Search. Básicamente es un todos contra todos. Disponible en Sklearn y Keras.
  - ¿Cómo evaluamos un modelo? ¿Con Train/test splot? ¿Con validación cruzada?
    - Held-Out (Test)
  - Random Search: va buscando combinaciones. Relación con K-Folds
    - Explicación de uso en Sklearn
- Automated Hyperparameter Tuning
  - Optimización Bayesiana. Se puede hacer en python con la biblioteca Hyperopt
  - Algoritmos Genéticos. Se puede hacer en python con TPOT.
  - ANN con Keras (con KerasClassifier)
- Guía para ordenar ideas

Tarea:

- Mirar video Hyperparameter tuning - Tuning process

Próxima clase:

- Se trabajará en el notebook de clase

Recursos (ver PPT para links)



Comentarios finales:

- Recordar que los prácticos se pueden entregar hasta el 6.

### Clase 2. 

### Keypoints

### Clase 3. 

### Keypoints



### Clase 4. 

### Keypoints



### Clase 5. 

### Keypoints



### Clase 6. 

### Keypoints

### Clase 7. 

### Keypoints



### Clase 8. 

### Keypoints