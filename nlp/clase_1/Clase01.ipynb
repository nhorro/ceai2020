{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 1. Ejercicios\n",
    "\n",
    "(Explicación en 02:40:14)\n",
    "\n",
    "#### Ejercicio 1\n",
    "\n",
    "Dado un corpus de documentos representados por una lista de textos, devolver una matriz con la representación one-hot-encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [ \n",
    "    \"hola como estas\", \n",
    "    \"hola como estas y como llego al subte\",\n",
    "    \"como llego al subte\",\n",
    "    \"esta palabra se repite mucho mucho mucho\"\n",
    "]\n",
    "\n",
    "def get_vocab_from_corpus(corpus):\n",
    "    return np.unique(list(chain.from_iterable(map(str.split, corpus))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['al', 'como', 'esta', 'estas', 'hola', 'llego', 'mucho', 'palabra',\n",
       "       'repite', 'se', 'subte', 'y'], dtype='<U7')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = get_vocab_from_corpus(corpus)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo. Ver un documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hola como estas'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = corpus[0]\n",
    "doc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expresar un documento cómo una lista de índices de un vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_indexes(doc,vocab):\n",
    "    splitted_doc = doc.split()\n",
    "    return np.array([np.where(vocab==x) for x in splitted_doc]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vocab_indexes(doc1,vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_doc(doc,vocab):\n",
    "    doc_ohe = np.zeros(vocab.size)\n",
    "    doc_ohe[get_vocab_indexes(doc,vocab)] = 1\n",
    "    return doc_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_encode_corpus(corpus,vocab):\n",
    "    corpus_ohe = np.zeros(shape=(len(corpus),vocab.size))\n",
    "    for idx, doc in enumerate(corpus):\n",
    "        corpus_ohe[idx] = one_hot_encode_doc(doc,vocab)\n",
    "    return corpus_ohe\n",
    "\n",
    "corpus_ohe = one_hot_encode_corpus(corpus,vocab)\n",
    "corpus_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2\n",
    "\n",
    "Dado un corpus de documentos representados por una lista de textos, devolver una matriz con la representación vectores de frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_encode_doc(doc,vocab):\n",
    "    doc_freq = np.zeros(vocab.size)\n",
    "    unique_idx,freq = np.unique(get_vocab_indexes(doc,vocab), return_counts=True)\n",
    "    doc_freq[unique_idx] = freq\n",
    "    return doc_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esta palabra se repite mucho mucho mucho\n",
      "[0. 0. 1. 0. 0. 0. 3. 1. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "doc2 = corpus[3]\n",
    "doc2\n",
    "print(doc2)\n",
    "print(freq_encode_doc(doc2,vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 2., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 3., 1., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def freq_encode_corpus(corpus,vocab):\n",
    "    corpus_freq = np.zeros(shape=(len(corpus),vocab.size))\n",
    "    for idx, doc in enumerate(corpus):\n",
    "        corpus_freq[idx] = freq_encode_doc(doc,vocab)\n",
    "    return corpus_freq\n",
    "\n",
    "corpus_freq = freq_encode_corpus(corpus,vocab)\n",
    "corpus_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 3\n",
    "\n",
    "Dado un corpus de documentos representados por una lista de textos, devolver una matriz con la representación TFIDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.46209812, 0.        , 0.69314718, 0.69314718,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.69314718, 0.92419624, 0.        , 0.69314718, 0.69314718,\n",
       "        0.69314718, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.69314718, 1.38629436],\n",
       "       [0.69314718, 0.46209812, 0.        , 0.        , 0.        ,\n",
       "        0.69314718, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.69314718, 0.        ],\n",
       "       [0.        , 0.        , 1.38629436, 0.        , 0.        ,\n",
       "        0.        , 4.15888308, 1.38629436, 1.38629436, 1.38629436,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidf(corpus,vocab):\n",
    "    # Term Frec - Inverse Doc Frec (02:18)\n",
    "    \n",
    "    # IDF\n",
    "    N = len(corpus)\n",
    "    corpus_ohe = one_hot_encode_corpus(corpus,vocab)\n",
    "    idf = np.log(N)/np.sum(corpus_ohe,axis=0) \n",
    "    \n",
    "    # TF\n",
    "    tf = freq_encode_corpus(corpus,vocab)\n",
    "    \n",
    "    return tf*idf\n",
    "\n",
    "tfidf(corpus,vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 4\n",
    "\n",
    "Escribir una función que reciba la matriz representando el corpus y el índice de un documento y devuelva los documentos ordenados por similitud coseno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(doc1,doc2):\n",
    "    return np.dot(doc1,doc2)/( np.linalg.norm(doc1) * np.linalg.norm(doc2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc': 'hola como estas', 'similarity': 0.9999999999999998},\n",
       " {'doc': 'hola como estas y como llego al subte',\n",
       "  'similarity': 0.5628285773640647},\n",
       " {'doc': 'como llego al subte', 'similarity': 0.15316791621349668},\n",
       " {'doc': 'esta palabra se repite mucho mucho mucho', 'similarity': 0.0}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sort_docs_by_cosine_similarity(corpus,doc_index):\n",
    "    vocab = get_vocab_from_corpus(corpus)\n",
    "    corpus_tf_idf = tfidf(corpus,vocab)\n",
    "    \n",
    "    N = len(corpus)\n",
    "    result = []\n",
    "    for i in range(N):\n",
    "        result.append( {\n",
    "            \"doc\": corpus[i],    \n",
    "            \"similarity\": cosine_similarity(corpus_tf_idf[i],corpus_tf_idf[doc_index])\n",
    "                \n",
    "        })    \n",
    "    return sorted(result, reverse = True, key=lambda e: e['similarity'])\n",
    "\n",
    "result = sort_docs_by_cosine_similarity(corpus,0)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 5\n",
    "\n",
    "Implementar (3) con matrices sparse de la librería SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hola como estas',\n",
       " 'hola como estas y como llego al subte',\n",
       " 'como llego al subte',\n",
       " 'esta palabra se repite mucho mucho mucho']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[1, 1, 1]\n",
      "[0, 1, 2, 0, 1, 2, 3, 1, 4, 5, 6]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 1, 2, 0, 1, 2, 3, 1, 4, 5, 6, 1, 4, 5, 6]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 1, 2, 0, 1, 2, 3, 1, 4, 5, 6, 1, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[[1 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 2 1 1 1 1 1 0 0 0 0 0]\n",
      " [0 1 0 0 1 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1 1 1 3]]\n",
      "{'hola': 0, 'como': 1, 'estas': 2, 'y': 3, 'llego': 4, 'al': 5, 'subte': 6, 'esta': 7, 'palabra': 8, 'se': 9, 'repite': 10, 'mucho': 11}\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import bsr_matrix,csr_matrix\n",
    "from itertools import chain\n",
    "\n",
    "def encode_corpus_sparse(corpus):\n",
    "    splitted_corpus = [x.split() for x in corpus]\n",
    "    indptr = [0]\n",
    "    indices = []\n",
    "    data = []\n",
    "    vocab = {}\n",
    "    for doc in splitted_corpus:\n",
    "        for term in doc:\n",
    "            index = vocab.setdefault(term, len(vocab))\n",
    "            indices.append(index)\n",
    "            data.append(1)\n",
    "        indptr.append(len(indices))\n",
    "        print(indices)\n",
    "        print(data)\n",
    "    encoded_corpus = csr_matrix((data, indices, indptr), dtype=int)\n",
    "    return encoded_corpus, vocab\n",
    "\n",
    "encoded_corpus, vocab = encode_corpus_sparse(corpus)\n",
    "print(encoded_corpus.toarray())\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME algo está mal acá. De dónde sale el último 3?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
